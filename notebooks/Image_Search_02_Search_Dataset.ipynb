{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gu-ma/hgk-ml-workshop/blob/main/notebooks/Image_Search_02_Search_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pl5Oa7xWdVS"
      },
      "source": [
        "# Search image in the Dataset\n",
        "\n",
        "With this notebook you can search for photos using natural language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z91T8JDUWlQI"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2tShWDdWifV"
      },
      "outputs": [],
      "source": [
        "! pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DOh447tel55"
      },
      "outputs": [],
      "source": [
        "import clip\n",
        "import torch\n",
        "\n",
        "# Load the open CLIP model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAA2cho0Wr1v"
      },
      "source": [
        "## Connect to Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l73Dm8jLWuG8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUhPVD32WdVT"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "You will need the Dataset and the precomputed feature vectors for this. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WnBYiLFWXR4C"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# @markdown Path to source directory on google drive. Right click your directory and choose \"copy path\" then paste it below.\n",
        "\n",
        "# @markdown ⚠️ __This is the folder with the scenes and images__ ⚠️\n",
        "gdrive_input_dir = \"/content/drive/MyDrive/AI/hgk_workshop/playlist01_output\"  # @param { type:'string' }\n",
        "\n",
        "# @markdown ⚠️ __This is the folder with the features saved when we processed the dataset__ ⚠️\n",
        "gdrive_clip_input_dir = \"/content/drive/MyDrive/AI/hgk_workshop/playlist01_output_clip\"  # @param { type:'string' }\n",
        "\n",
        "# Some other dir / vars\n",
        "(gdrive_path, gdrive_folder) = os.path.split(gdrive_input_dir)\n",
        "\n",
        "input_dir = gdrive_folder\n",
        "output_dir = f'{gdrive_folder}_clip'\n",
        "\n",
        "gdrive_output_dir = os.path.join(gdrive_path, output_dir)\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Copy all jpg locally\n",
        "! cp -r {gdrive_input_dir}/*.jpg {input_dir}\n",
        "\n",
        "# Copy features\n",
        "shutil.copytree(gdrive_clip_input_dir, output_dir, dirs_exist_ok=True)\n",
        "\n",
        "# Set the path to the photos\n",
        "photos_path = Path(input_dir)\n",
        "\n",
        "# List all JPGs in the folder\n",
        "photos_files = list(photos_path.glob(\"*.jpg\"))\n",
        "photos_files.sort()\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Photos found: {len(photos_files)}\")\n",
        "print(*photos_files[:10], sep='\\n')\n",
        "\n",
        "# Path where the feature vectors will be stored\n",
        "features_path = Path(output_dir)\n",
        "\n",
        "# Load the features and the corresponding IDs\n",
        "photo_features = np.load(features_path / \"features.npy\")\n",
        "photo_ids = pd.read_csv(features_path / \"photo_ids.csv\")\n",
        "photo_ids = list(photo_ids['photo_id'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWY0vy4SWdVU"
      },
      "source": [
        "## Search\n",
        "\n",
        "Specify your search query and encode it to a feature vector using CLIP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "QbLCNzrtWdVV"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "search_query = \"A man with a blue shirt\" #@param {type:\"string\"}\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Encode and normalize the description using CLIP\n",
        "    text_encoded = model.encode_text(clip.tokenize(search_query).to(device))\n",
        "    text_encoded /= text_encoded.norm(dim=-1, keepdim=True)\n",
        "\n",
        "# Compare the text features to the image features and find the best match.\n",
        "\n",
        "# Retrieve the description vector and the photo vectors\n",
        "text_features = text_encoded.cpu().numpy()\n",
        "\n",
        "# Compute the similarity between the descrption and each photo using the Cosine similarity\n",
        "similarities = (text_features @ photo_features.T).squeeze(0).tolist()\n",
        "\n",
        "# Sort the photos by their similarity score\n",
        "best_photos = sorted(zip(similarities, range(photo_features.shape[0])), key=lambda x: x[0], reverse=True)\n",
        "\n",
        "# Show results\n",
        "\n",
        "# Iterate over the top 3 results\n",
        "for i in range(3):\n",
        "    # Retrieve the photo ID\n",
        "    pct, idx = best_photos[i]\n",
        "    photo_id = photo_ids[idx]\n",
        "\n",
        "    # Display the photo\n",
        "    display(Image(photos_files[idx]))\n",
        "    print(pct, idx, photos_files[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7u6BZrtoZM8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "z91T8JDUWlQI",
        "pAA2cho0Wr1v"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}